# Hackaton - Video Processing Consumer Service

Servi√ßo Quarkus para processamento de v√≠deos a partir de eventos Kafka: baixa chunks do Azure Blob Storage, extrai frames em PNG, controla progresso no Redis, gera um ZIP com os frames ao final e publica status no Kafka.

## Funcionalidades

- **Consumo Kafka**: Consome mensagens com metadados do v√≠deo/chunk no canal `video-split`.
- **Download de Chunk**: Busca o chunk no Azure Blob Storage.
- **Extra√ß√£o de Frames**: Extrai frames com JCodec, amostrando a cada N frames (configur√°vel).
- **Persist√™ncia de Frames**: Salva frames `.png` no Azure Blob por usu√°rio/v√≠deo.
- **Controle de Progresso**: Usa Redis para acompanhar chunks processados e orquestrar o zip final.
- **Gera√ß√£o de ZIP**: Ao completar todos os chunks, cria `frames.zip` com todos os frames e limpa blobs intermedi√°rios.
- **Publica√ß√£o de Status**: Emite eventos de sucesso/erro em t√≥pico Kafka configur√°vel.
- **Health Check**: SmallRye Health exposto via Quarkus.

## Formatos de V√≠deo Suportados

- Compat√≠veis com JCodec (recomendado: MP4/H.264).

## Stack Tecnol√≥gico

- **Java 21**
- **Quarkus 3.25.4**
- **SmallRye Reactive Messaging (Kafka)**
- **Azure Blob Storage SDK**
- **Redis (Quarkus Redis Client)**
- **JCodec/JCodec-JavaSE**
- **ModelMapper**
- **Maven**, **Docker & Docker Compose**
- **JUnit 5**, Mockito, **JaCoCo**

## Arquitetura

![image](https://github.com/user-attachments/assets/c8996715-f174-4611-ab40-7c1d5ba35877)
Considerando Clean Architecture:
- As camadas `presentation`/`infrastructure` equivalem a Framework & Drivers (consumer Kafka, adapters Azure/Kafka/Redis).
- A camada `application` cont√©m orquestra√ß√£o/casos de uso/mapeadores.
- A camada `domain` representa as entidades.

## Estrutura√ß√£o das pastas

```
src/main/java/br/com/video/processing/
‚îú‚îÄ‚îÄ presentation/
‚îÇ   ‚îî‚îÄ‚îÄ kafka/
‚îÇ       ‚îú‚îÄ‚îÄ VideoProcessingConsumer.java
‚îÇ       ‚îî‚îÄ‚îÄ impl/VideoProcessingConsumerImpl.java
‚îú‚îÄ‚îÄ application/
‚îÇ   ‚îú‚îÄ‚îÄ controller/ (VideoProcessingController, Impl)
‚îÇ   ‚îú‚îÄ‚îÄ usecase/ (GetVideoUseCase, ExtractFramesUseCase, CompleteChunkUseCase, PublishVideoStatusUseCase, impl/)
‚îÇ   ‚îî‚îÄ‚îÄ mapper/ (RequestVideoInfoMapper, impl/)
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ kafka/ (VideoStatusProducer, impl/KafkaVideoStatusProducer)
‚îÇ   ‚îú‚îÄ‚îÄ azure/storage/adapter/ (AzureBlobGenericPersister, AzureBlobVideoStorageFetcher, AzureFramesZipperService)
‚îÇ   ‚îî‚îÄ‚îÄ redis/ (RedisChunkProgressRepository)
‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îú‚îÄ‚îÄ domain/dto/event/ (VideoStatusEvent)
‚îÇ   ‚îú‚îÄ‚îÄ domain/dto/request/ (UploadedVideoInfoDto)
‚îÇ   ‚îî‚îÄ‚îÄ interfaces/ (BlobStoragePersister, VideoStorageFetcher, ChunkProgressRepository, FramesZipper)
‚îî‚îÄ‚îÄ domain/
    ‚îî‚îÄ‚îÄ VideoChunkInfo
```

## üöÄ In√≠cio R√°pido

### Pr√©-requisitos

- Docker e Docker Compose
- Java 21
- Maven 3.8+

### Vari√°veis de ambiente / Secrets (Local vs Kubernetes)

Este projeto usa vari√°veis relacionadas a Kafka (Event Hubs), Redis e par√¢metros internos:

- `KAFKA_BOOTSTRAP_SERVERS` (default `kafka:9092`)
- `KAFKA_SECURITY_PROTOCOL` (default `SASL_SSL`)
- `KAFKA_SASL_MECHANISM` (default `PLAIN`)
- `KAFKA_SASL_JAAS_CONFIG` (sens√≠vel)
- `KAFKA_AUTO_OFFSET_RESET` (default `latest`)
- `KAFKA_CONSUMER_GROUP` (default `video-processing`)
- `VIDEO_SPLITTED_TOPIC` (default `video.split`)
- `VIDEO_STATUS_TOPIC` (default `video.status`)
- `VIDEO_FRAMES_SAMPLE_EVERY_N_FRAMES` (default `30`)
- `REDIS_HOSTS` (default `redis://localhost:6379` ou `redis://redis:6379` no Compose)
- `REDIS_USERNAME`, `REDIS_PASSWORD` (opcionais)
- `REDIS_CHUNK_TTL_SECONDS` (default `600`)

No Kubernetes usamos `kubernetes/Secret.yaml` (chaves em `stringData`). No ambiente local (Docker Compose) usamos um arquivo `.env`.

### Limita√ß√£o importante

O Docker Compose N√ÉO l√™ diretamente um `Secret.yaml` do Kubernetes. Converta para `.env` ou declare manualmente em `docker-compose.yml`.

### Scripts auxiliares

1. `scripts/env-from-secret.ps1`
   - Converte `kubernetes/Secret.yaml` (stringData) em um arquivo `.env`.
   - Uso:
     ```powershell
     powershell -ExecutionPolicy Bypass -File scripts/env-from-secret.ps1 -SecretPath kubernetes/Secret.yaml -OutFile .env
     ```

2. `scripts/secret-from-env.ps1`
   - Gera `kubernetes/Secret.yaml` a partir de um `.env` (fonte de verdade local).
   - Uso:
     ```powershell
     powershell -ExecutionPolicy Bypass -File scripts/secret-from-env.ps1 -EnvPath .env -SecretPath kubernetes/Secret.yaml
     ```

### Executando com Docker Compose

O arquivo `docker-compose.yml` j√° referencia:

```yaml
env_file:
  - .env
```

Passos:

```bash
# 1. Gerar/atualizar .env (editar manualmente ou via script)
# 2. Build do app (gera target/quarkus-app)
mvn -DskipTests package
# 3. Subir o stack
docker compose up -d --build
# 4. Logs
docker compose logs -f app
```

## üîß Configura√ß√£o Quarkus

- HTTP root path: `quarkus.http.root-path=/video-processing`
- Health: `GET /video-processing/q/health`
- Config dos canais Kafka em `src/main/resources/application.properties`:
  - Incoming: `video-split` ‚Üí t√≥pico `${VIDEO_SPLITTED_TOPIC}`
  - Outgoing: `video-events` ‚Üí t√≥pico `${VIDEO_STATUS_TOPIC}`

## üîÑ Fluxo de Processamento

1. Consumer `video-split` recebe `UploadedVideoInfoDto` com:
   - `videoId`, `userId` (UUID), `containerName`, `connectionString`, `fileName`, `chunkPosition`, `totalChunks`.
2. `GetVideoUseCase` busca o blob do chunk:
   - Path esperado: `"{videoId}/chunks/{fileName}"`.
3. `ExtractFramesUseCaseImpl` extrai frames e salva PNG no Azure:
   - Path: `"{userId}/{videoId}/part_{chunkPosition}_frame_{index}.png"`.
4. `CompleteChunkUseCaseImpl` atualiza progresso no Redis e, se completou todos os chunks:
   - `AzureFramesZipperService.zipFrames()` gera `frames.zip` e remove blobs intermedi√°rios.
5. `KafkaVideoStatusProducer` publica evento no t√≥pico `${VIDEO_STATUS_TOPIC}`:
   - `SUCCESS` ao finalizar zip; `ERROR` em caso de falha.

## üì® Exemplos de Mensagens Kafka

### Incoming (video-split) ‚Üí `UploadedVideoInfoDto`

T√≥pico: `${VIDEO_SPLITTED_TOPIC}` (default `video.split`)

Key (opcional): `videoId` como string

Payload (JSON):

```json
{
  "videoId": 12345,
  "userId": "550e8400-e29b-41d4-a716-446655440000",
  "containerName": "videos-container",
  "connectionString": "DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net",
  "fileName": "chunk_0001.mp4",
  "chunkPosition": 1,
  "totalChunks": 10
}
```

Exemplo com `kafka-console-producer`:

```bash
# sem headers
kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic video.split <<'EOF'
{"videoId":12345,"userId":"550e8400-e29b-41d4-a716-446655440000","containerName":"videos-container","connectionString":"<conn>","fileName":"chunk_0001.mp4","chunkPosition":1,"totalChunks":10}
EOF
```

### Outgoing (video-events) ‚Üí `VideoStatusEvent`

T√≥pico: `${VIDEO_STATUS_TOPIC}` (default `video.status`)

Key (definida): `videoId` como string

Payload (JSON):

```json
{
  "userId": "550e8400-e29b-41d4-a716-446655440000",
  "videoId": 12345,
  "status": "SUCCESS"
}
```

Exemplo de consumo com `kafka-console-consumer`:

```bash
kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic video.status \
  --from-beginning \
  --property print.key=true \
  --property key.separator="," \
  --timeout-ms 30000
```

## üê≥ Servi√ßos Docker

O ambiente de desenvolvimento inclui:

- **Kafka 3.6 (Bitnami)**
- **Redis 7.0**
- **App Quarkus** (monta `./target/quarkus-app`)

Arquivo: `docker-compose.yml`

## üß™ Testes

```bash
mvn test
```

Relat√≥rios de cobertura com JaCoCo.

## üìö Documenta√ß√£o

- **Config Quarkus**: `src/main/resources/application.properties`
- **Health Checks**: `GET /video-processing/q/health`
- **Mensageria**:
  - Incoming: canal `video-split` ‚Üí t√≥pico `${VIDEO_SPLITTED_TOPIC}`
  - Outgoing: canal `video-events` ‚Üí t√≥pico `${VIDEO_STATUS_TOPIC}`

## Cobertura Sonar
![sonar.png](assets/images/sonar.png)

## Arquitetura Infraestrutura

### Diagrama de Fluxo
![infra.jpg](assets/images/infra.jpg)
- Dentro do Resource Group techchallenge-rg, h√° um IP P√∫blico que acessa o APIM (Azure API Management)
- Quando acessado e havendo configura√ß√£o de suas pol√≠ticas realiza a chamada para a function.
- O Ingress Controller ent√£o roteia as requisi√ß√µes para os diferentes servi√ßos internos a depender da URI chamada, utilizando a comunica√ß√£o via Cluster IP.
- As aplica√ß√µes java se comunicam com seus respectivos databases utilizando a comunica√ß√£o via Cluster IP.
  Obs: Para saber mais sobre o recurso Standard_B2S: https://learn.microsoft.com/pt-br/azure/virtual-machines/sizes/general-purpose/bv1-series?tabs=sizebasic

### Diagrama de Componente
![pods.jpg](assets/images/pods.jpg)
O cluster k8s-fiap √© configurado com dois namespaces principais, cada um com fun√ß√µes espec√≠ficas:
- default: Namespace onde as aplica√ß√µes principais s√£o implantadas e gerenciadas, contendo os PODs:
    - java-app-*: microsservi√ßo presente no cluster.
        - Ingress: Configurado para gerenciar o tr√°fego de entrada direcionado √† aplica√ß√£o Java.
        - Cluster IP: Endere√ßo IP interno para comunica√ß√£o dentro do cluster.
        - Deployment: Gerencia a implanta√ß√£o e a escalabilidade da aplica√ß√£o Java.
        - Secret: Armazena dados sens√≠veis, como chaves de API ou credenciais usadas pela aplica√ß√£o.
        - Horizontal Pod Autoscaler (HPA): Configurado para escalar automaticamente o n√∫mero de r√©plicas do pod com base na utiliza√ß√£o de CPU.
        - Configura√ß√£o do HPA:
            - M√≠nimo de 1 e m√°ximo de 3 r√©plicas.
            - Escala a partir da m√©trica de uso de CPU atingir 70%.
        - Role HPA: Define as permiss√µes necess√°rias para que o HPA acesse m√©tricas do cluster (como CPU e mem√≥ria) para tomar decis√µes de escalabilidade.
- ingress-basic: √© respons√°vel por gerenciar o tr√°fego externo e rotear as requisi√ß√µes para os servi√ßos no namespace default.
    - ingress-nginx-controller: Executa o controlador NGINX Ingress, que atua como ponto de entrada para requisi√ß√µes externas e roteia o tr√°fego para os servi√ßos apropriados no namespace default.
        - Ingress: Define as regras de roteamento para requisi√ß√µes externas (por exemplo, rotear requisi√ß√µes para o servi√ßo do java-app).
        - Service: Exp√µe o controlador NGINX internamente no cluster.
        - Endpoint: Mapeia os endpoints para os servi√ßos internos.
        - Deployment: Gerencia a implanta√ß√£o do controlador NGINX.
        - ConfigMap: Armazena configura√ß√µes do NGINX, como limites de requisi√ß√µes, timeouts e outras op√ß√µes de personaliza√ß√£o.
        - Secret: Armazena informa√ß√µes sens√≠veis, como certificados TLS para habilitar HTTPS.    
          *Os arquivos de configura√ß√£o do Kubernetes (em formato .yml) est√£o organizados no diret√≥rio `kubernetes/`.
